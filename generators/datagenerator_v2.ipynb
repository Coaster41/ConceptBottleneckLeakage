{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def multi_label_acc(y_hat, y):\n",
    "    return torch.count_nonzero(torch.round(y_hat) == y).item() / y.numel()\n",
    "\n",
    "def classification_acc(y_hat, y):\n",
    "    return torch.count_nonzero(torch.argmax(y_hat, dim=1) == y).item() / y.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_x = 64\n",
    "num_c = 16\n",
    "num_y = 10\n",
    "k = 0.875 # ratio of x's to use to calculate concepts\n",
    "num_xc = int(k * num_x)\n",
    "num_samples = 10**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinarySigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinarySigmoid, self).__init__()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'BinarySigmoid()'\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.sigmoid(x)\n",
    "        return x + torch.round(x).detach() - x.detach()\n",
    "    \n",
    "def init_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            nn.init.normal_(m.bias)\n",
    "            m.requires_grad_(False)\n",
    "\n",
    "x_to_c = nn.Sequential(\n",
    "    nn.Linear(num_xc, 32),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(32, 32),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(32, num_c)\n",
    ")\n",
    "\n",
    "xc_to_y = nn.Sequential(\n",
    "    nn.Linear(num_x-num_xc+num_c, 32),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(32, num_y)\n",
    ")\n",
    "\n",
    "xc_activation = BinarySigmoid()\n",
    "cy_activation = nn.Softmax(dim=1)\n",
    "\n",
    "init_weights(x_to_c)\n",
    "init_weights(xc_to_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([ 8618,  8669,  7904,  6727, 10109, 14912,  8984, 12321, 11590, 10166]))\n"
     ]
    }
   ],
   "source": [
    "def gen_x(num_x, batch_size):\n",
    "    return torch.rand((batch_size, num_x))\n",
    "\n",
    "x = gen_x(num_x, num_samples)\n",
    "c_logits = x_to_c(x[:,:num_xc])\n",
    "mean_c_logits = torch.mean(c_logits, dim=0)\n",
    "x_to_c[-1].bias -= mean_c_logits\n",
    "c_logits = x_to_c(x[:,:num_xc])\n",
    "c = xc_activation(c_logits)\n",
    "y_logits = xc_to_y(torch.concat((x[:,num_xc:],c), dim=1))\n",
    "mean_y_logits = torch.mean(y_logits, dim=0)\n",
    "xc_to_y[-1].bias -= mean_y_logits\n",
    "y_logits = xc_to_y(torch.concat((x[:,num_xc:],c), dim=1))\n",
    "# y = cy_activation(y_logits)\n",
    "y = cy_activation(y_logits / torch.std(y_logits, dim=0))\n",
    "y_argmax = torch.argmax(y, dim=1)\n",
    "print(torch.unique(y_argmax, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_to_new_x = nn.Sequential(\n",
    "    nn.Linear(num_x, num_x)\n",
    ")\n",
    "init_weights(x_to_new_x)\n",
    "new_x = x_to_new_x(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_to_c_test = nn.Sequential(\n",
    "    nn.Linear(num_x, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, num_c),\n",
    "    nn.Sigmoid()\n",
    ").to(device)\n",
    "\n",
    "xc_to_y_test = nn.Sequential(\n",
    "    nn.Linear(num_c, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, num_y),\n",
    "    nn.Softmax(dim=1)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3597686290740967 y_acc: 0.72986875\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 10**4\n",
    "y_criterion = nn.CrossEntropyLoss()\n",
    "c_criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(x_to_c_test.parameters(), lr=0.001)\n",
    "loss_meter = AverageMeter()\n",
    "acc_meter = AverageMeter()\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_meter.reset()\n",
    "    acc_meter.reset()\n",
    "    for index in range(num_samples//batch_size-1):\n",
    "        X, C, Y = new_x[index*batch_size:(index+1)*batch_size].to(device), c[index*batch_size:(index+1)*batch_size].to(device), y_argmax[index*batch_size:(index+1)*batch_size].to(device)\n",
    "        c_pred = x_to_c_test(X)\n",
    "        c_loss = c_criterion(c_pred, C)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        c_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_meter.update(c_loss.item(), X.shape[0])\n",
    "        acc_meter.update(multi_label_acc(c_pred, C), X.shape[0])\n",
    "    # print(f\"Epoch: {epoch} Loss: {loss_meter.avg} y_acc: {acc_meter.avg}\")\n",
    "\n",
    "loss_meter.reset()\n",
    "acc_meter.reset()\n",
    "index = num_samples//batch_size-1\n",
    "X, C, Y = new_x[index*batch_size:(index+1)*batch_size].to(device), c[index*batch_size:(index+1)*batch_size].to(device), y_argmax[index*batch_size:(index+1)*batch_size].to(device)\n",
    "c_pred = x_to_c_test(X)\n",
    "c_loss = c_criterion(c_pred, C)\n",
    "\n",
    "loss_meter.update(c_loss.item(), X.shape[0])\n",
    "acc_meter.update(multi_label_acc(c_pred, C), X.shape[0])\n",
    "print(f\"Test Loss: {loss_meter.avg} y_acc: {acc_meter.avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.085350275039673 y_acc: 0.3687\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(xc_to_y_test.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_meter.reset()\n",
    "    acc_meter.reset()\n",
    "    for index in range(num_samples//batch_size-1):\n",
    "        X, C, Y = new_x[index*batch_size:(index+1)*batch_size].to(device), c[index*batch_size:(index+1)*batch_size].to(device), y_argmax[index*batch_size:(index+1)*batch_size].to(device)\n",
    "        c_pred = torch.round(x_to_c_test(X))\n",
    "        y_pred = xc_to_y_test(c_pred)\n",
    "        y_loss = y_criterion(y_pred, Y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_meter.update(y_loss.item(), X.shape[0])\n",
    "        acc_meter.update(classification_acc(y_pred, Y), X.shape[0])\n",
    "    # print(f\"Epoch: {epoch} Loss: {loss_meter.avg} y_acc: {acc_meter.avg}\")\n",
    "\n",
    "loss_meter.reset()\n",
    "acc_meter.reset()\n",
    "index = num_samples//batch_size-1\n",
    "X, C, Y = new_x[index*batch_size:(index+1)*batch_size].to(device), c[index*batch_size:(index+1)*batch_size].to(device), y_argmax[index*batch_size:(index+1)*batch_size].to(device)\n",
    "c_pred = torch.round(x_to_c_test(X))\n",
    "y_pred = xc_to_y_test(c_pred)\n",
    "y_loss = y_criterion(y_pred, Y)\n",
    "\n",
    "loss_meter.update(y_loss.item(), X.shape[0])\n",
    "acc_meter.update(classification_acc(y_pred, Y), X.shape[0])\n",
    "print(f\"Test Loss: {loss_meter.avg} y_acc: {acc_meter.avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cbm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
